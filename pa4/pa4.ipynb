{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6b9095",
   "metadata": {},
   "source": [
    "# CSE 151A - PA4\n",
    "By: Jonathan Lo<br>\n",
    "Date: 8/3/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781fcd3",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e48fc",
   "metadata": {},
   "source": [
    "### Q1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd9051",
   "metadata": {},
   "source": [
    "**Original Version**:\n",
    "![Original Version](https://cdn.discordapp.com/attachments/942218891952783421/1136702566848270437/image.png)\n",
    "\n",
    "**Normalized Version**:\n",
    "![Normalized Version](https://cdn.discordapp.com/attachments/942218891952783421/1136702584833441853/HdhRMpgMBgMXYsRKYPBYDB0LUakDAaDwdC1GJEyGAwGQ9diRMpgMBgMXYsRKYPBYDB0LUakDAaDwdC1GJEyGAwGQ9diRMpgMBgMXYsRKYPBYDB0Lf8HMHqoZe3IpicAAAAASUVORK5CYII.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa2642",
   "metadata": {},
   "source": [
    "### Q1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a387a",
   "metadata": {},
   "source": [
    "![](https://cdn.discordapp.com/attachments/942218891952783421/1136705746759864410/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2893db",
   "metadata": {},
   "source": [
    "### Q2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.to(device)\n",
    "        input_var = torch.autograd.Variable(input).to(device)\n",
    "        target_var = torch.autograd.Variable(target).to(device)\n",
    "        # target_var = torch.squeeze(target_var)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(output, target_var.long())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1[0][0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            curr_lr = optimizer.param_groups[0]['lr']\n",
    "            print('Epoch: [{0}/{1}][{2}/{3}]\\t'\n",
    "                  'LR: {4}\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Train Acc {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   epoch, num_epochs, i, len(train_loader), curr_lr,\n",
    "                   loss=losses, top1=top1))\n",
    "\n",
    "    # Return the average training loss for the current epoch\n",
    "    return losses.avg\n",
    "\n",
    "best_prec1 = 0\n",
    "total_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch in lr_step:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "\n",
    "    # train for one epoch\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss.append(train_loss)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    # prec1 = 0\n",
    "    prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best,filename=\"checkpoint.pth.tar\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    # if epoch%print_freq==0:\n",
    "    #     plot_decision_boundary(model)\n",
    "\n",
    "# plot_decision_boundary(model)\n",
    "plt.plot(range(1, num_epochs + 1), total_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs. Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac3474",
   "metadata": {},
   "source": [
    "![](https://cdn.discordapp.com/attachments/942218891952783421/1136711194988773477/wftWjtosO5yxAAAAABJRU5ErkJggg.png)\n",
    "\n",
    "It looks like there are occasionally big spikes in loss. However, there is a general downward trend as the number of epochs increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e27f35",
   "metadata": {},
   "source": [
    "### Q2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a82aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch in lr_step:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= lr\n",
    "\n",
    "        # Train for one epoch and get the average loss for this epoch\n",
    "        train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_accuracy = validate(val_loader, model, criterion)\n",
    "\n",
    "        # Store the accuracy for each epoch\n",
    "        train_accuracies.append(train_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, train_accuracies[i * num_epochs : (i + 1) * num_epochs], label=f\"Train LR={lr}\")\n",
    "    plt.plot(epochs, val_accuracies[i * num_epochs : (i + 1) * num_epochs], label=f\"Val LR={lr}\", linestyle='dashed')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for Different Learning Rates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086ce74",
   "metadata": {},
   "source": [
    "![](https://cdn.discordapp.com/attachments/942218891952783421/1136714751741796373/0gERH1SnxqHxER9VmKomDHjh149NFHzQ6FiIj6GH5HioiIiIiIyEcspIiIiIiIiHzE70gREVGfxbvXiYjIKLwiRURERERE5CMWUkRERERERD5iIUVEREREROQjFlJEREREREQYiFFRERERETkIxZSREREREREPmIhRURERERE5CMWUkRERERERD76P8nTw5I8NWGRAAAAAElFTkSuQmCC.png)\n",
    "\n",
    "The best learning rate is `0.1` becuase the accuracy continues to increase through each epoch. The otheres remain constant  or dive down wildly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43041e1a",
   "metadata": {},
   "source": [
    "### Q2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = [\n",
    "    linear_nn([2,20,10,10,2],activations).to(device),\n",
    "    linear_nn([2,100,2],activations).to(device)\n",
    "]\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "for model in models:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch in lr_step:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= lr\n",
    "\n",
    "    # Get final accuracies\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_accuracy = validate(val_loader, model, criterion)\n",
    "\n",
    "    # Store the accuracy for each epoch\n",
    "    train_accuracies.append(train_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print(\"-----------------------\")\n",
    "print(\"Deep Model:\")\n",
    "print(\"Final Training Accuracy:\", train_accuracies[0])\n",
    "print(\"Final Testing Accuracy:\", val_accuracies[0])\n",
    "print(\"Num Params\": sum(p.numel() for p in models[0].parameters()))\n",
    "\n",
    "print(\"Shallow Model:\")\n",
    "print(\"Final Training Accuracy:\", train_accuracies[1])\n",
    "print(\"Final Testing Accuracy:\", val_accuracies[1])\n",
    "print(\"Num Params\": sum(p.numel() for p in models[1].parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b47d6f",
   "metadata": {},
   "source": [
    "```\n",
    "Deep Model:\n",
    "Final Training Accuracy: 0.700875997543335\n",
    "Final Testing Accuracy: 0.501231669087068\n",
    "Num Params: 402\n",
    "\n",
    "Shallow Model:\n",
    "Final Training Accuracy: 0.6991315722465515\n",
    "Final Testing Accuracy: 0.7566677862757319\n",
    "Num Params: 502\n",
    "```\n",
    "\n",
    "Although the deep model has a better training accuracy, the best model will be the shallow model because it has a better final testing accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
